## Bayesian Methods for Neural Networks
<br />
**Contacts**: <br />
Ekaterina Lobacheva - lobacheva.tjulja@gmail.com  <br />
Ilia Yakubovsky - ilia.yakubovskiy@yandex.ru <br />

Please, add tag **[BayesBootcamp]** to all the emails.

**Materials:** <br />
1. *(russian)* Ветров Д.П., Кропотов Д.А. Байесовские методы машинного обучения: [часть 1](http://www.machinelearning.ru/wiki/images/e/e1/BayesML-2007-textbook-1.pdf), 
[часть 2](http://www.machinelearning.ru/wiki/images/4/43/BayesML-2007-textbook-2.pdf).<br />
2. *(russian)* [Wiki page of the Bayesian metods course at CS MSU](http://www.machinelearning.ru/wiki/index.php?title=%D0%91%D0%BC%D0%BC%D0%BE). <br />
3. Christopher M. Bishop. [Pattern Recognition and Machine Learning]
(http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf).


## Syllabus  <br />
**Day 1.** <br />
* Bayesian methods: introduction, bayesian reasoning. Seminar: how to work with probabilities in bayesian paradigm.
* Analytical bayesian inference, conjugate distributions, exponential family. Seminar: inference in models with conjugate distributions.  
* Bayesian linaer regression.

*Additional materials (russian):* [notes](http://www.machinelearning.ru/wiki/images/8/8c/Lecture7_2012.pdf), 
    [problems 1](http://www.machinelearning.ru/wiki/images/1/18/S01_bayesian_reasoning_2016.pdf),
    [problems 2](http://www.machinelearning.ru/wiki/images/2/23/BMML_sem2_2016.pdf)

**Day 2.** <br />
* Expectation–maximization (EM) algorithm. EM for Gaussian mixture. 
* PCA and Bayesian PCA.
* Practice: ЕМ-algorithm for the investigation.

*Additional materials (russian):* [notes](http://www.machinelearning.ru/wiki/images/7/73/BMMO11_11.pdf)
  
**Day 3.** <br />
* Variational inference. Seminar: examples of usage for different models. 
* How to use bayesian inference in real life and how to choose which method to use. 
* Latent Dirichlet allocation

*Additional materials (russian):* [notes 1](http://www.machinelearning.ru/wiki/images/6/60/BMMO14_variational_lecture.pdf),
  [notes 2](http://www.machinelearning.ru/wiki/images/5/57/BMMO11_9.pdf),
  [notes 3](http://www.machinelearning.ru/wiki/images/8/82/BMMO11_14.pdf).

**Day 4.** <br />
* Stochastic variational inference. 
* [VAE](https://arxiv.org/abs/1312.6114) 
* [IWAE](https://arxiv.org/abs/1509.00519) – way to improve ELBO  
* [Normalizing flows](https://arxiv.org/pdf/1505.05770.pdf) – way to improve posterior distribution  
* Practice: variational autoencoders.

**Day 5.** <br />
* [Bayesian neural network](https://arxiv.org/abs/1505.05424) 
* [Variational dropout](https://arxiv.org/abs/1506.02557) 
* [Soft Weight-Sharing for Neural Network Compression](https://arxiv.org/abs/1702.04008) 
* [Variational Dropout Sparsifies Deep Neural Networks](https://arxiv.org/abs/1701.05369) 
* Summary of the course.
